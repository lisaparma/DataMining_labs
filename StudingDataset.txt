1. Studiare il dataset, guardare le variabili, comprendere le informazioni.

# Documentazione del dataset fornitoci da RStudio
?Boston

# Elenca i nomi delle varie colonne, i tipi e degli esempi di dato
str(Boston)


# Salviamoci i numeri delle entry (in questo caso delle case)
n <- nrow(Boston)

# Dataset solo con i valori che ci interessano
select <- c("crim", "zn")  # c() combina i valori per creare un vettore
newDataset <- Boston[,select]

# Guardiamo solo i dati che ci interessano e studiamoli
Boston[,3]
summary(Boston$medv) # Riassunto della colonna data, dipende dal tipo di oggetto passatogli
TODO: cosa possiamo dire dai dati che otteniamo qui?



2. Studiare graficamente i dati che abbiamo.

# Istogramma della distribuzione:
hist(Boston$medv, prob=TRUE, xlab='Median value', main='Histogram')

Boxplot della distribuzione:
# boxplot(Boston$medv, xlab='Median value', main='Boxplot' )


Relazione tra le variabili che ci interessano:
# Grafico di dispersione
plot(Boston$medv, Boston$lstat, main='Dispersion plot', xlab='% of lower status of the population', ylab='Median value', pch=19, cex=0.5)
# Da questo grafico possiamo trovare una relazione tra le variabili (tipp una relazione inversa). Lo veriamo anche calcolando la correlazione
cor(Boston$medv, Boston$lstat)


# Costruire un modello lineare semplice

# Metodo manuale
n # n. righe
covXY <- cov(Boston$medv, Boston$lstat)
vX <- var(Boston$lstat)*(n-1)/n
beta1 <- covXY/vX
beta0 <- mean(Boston$medv) - beta1*mean(Boston$lstat)

# Tramite R
mod1 <- lm(formula = medv ~ lstat, data=Boston)

summary(mod1)
# informazioni sui residui
# stime, standard error, significance test sui parametri
# informazioni dull'accuratezza del modello
# test F per la significità di tutti i parametri

# Altri dati
names(mod1)

# Grafici con dati aggiunti dal modello
plot(Boston$lstat, Boston$medv, pch=19, cex=0.5, xlab='% of lower status of the population', ylab='Median value')

points(Boston$lstat, est.values, pch='x', col='green') # aggiungo i valori stimati

abline(coef(model)[1], coef(model)[2], lty=2, col='red', lwd=3) # aggiungo la least squares regression line
oppure
abline(beta0, beta1, lty=2, col='red')

# residui
par(mfrow=c(2,2)) # Suddivisione in 4
res <- residuals(model)

hist(res, prob=TRUE) # istogramma dei residui

plot(res, pch=19, cex=0.5, ylab='Residuals') # grafico di dispersione
abline(h=0, lty=2)

plot(est.values, res, pch=19, cex=0.5, xlab='Estimated values',ylab='Residuals')
abline(h=0, lty=2)

plot(Boston$lstat, res, ylab='Residuals', xlab='% of lower status of the population', pch=19, cex=0.5)
abline(h=0, lty=2)



# Valutazione grafica dei residui standardizzati

par(mfrow=c(2,2))
standard.res <- rstandard(model)

hist(standard.res, prob=TRUE, xlab='Standardized residuals')

plot(standard.res, pch=19, cex=0.5, ylab='Standardized residuals')
abline(h=0, lty=2)

plot(est.values, standard.res, pch=19, cex=0.5, xlab='Estimated values', ylab='Standardized residuals')
abline(h=0, lty=2)

plot(Boston$lstat, standard.res, ylab='Standardized residuals', xlab='% of lower status of the population', pch=19, cex=0.5)
abline(h=0, lty=2)

# Valutazione grafica dell'accuratezza del modello
par(mfrow=c(2,2))
plot(model)

Guardare se ci sono valori anomali


1.1 Multiple linear regression modello (medv = β 0 + β 1 lstat + β 2 crim + ε)

plot(Boston$crim, Boston$medv, ylab='Median value'+ xlab='Crime', pch=19, cex=0.5)

model.mv <- lm(medv ~ lstat + crim, data=Boston)
summary(model.mv)


1.2 Modello polinomiale (medv = β 0 + β 1 lstat + β 2 lstat 2 + ε)
inseriamo un termine quadratico
model2 <- lm(medv ~ lstat + I(lstat^2), data=Boston)

Comparare i due modelli usando la F statistic

rss0 <- (6.216^2)*504
rss <- (5.524^2)*503
f <- (rss0 - rss)/rss * (503/1)

qf(0.95, 1, 503)

se qf è molto diverso da 0:
There is empirical evidence against H0 that suggests to move to the simplest model with a single covariate

p-value:
1-pf(f, 1, 503)
[1] 0
> ## the p-value confirms the rejection of H0


# Function anova
anova(model, model2)




# REGRESSIONE lineare
controllare se una variabile è qualitativa
is.factor(my.data$Gender)

controllare i suoi livelli
levels(my.data$Gender)

e i suoi valori
table(my.data$Gender)


# Analisi grafica
boxplot(my.data$Salary, las=2, col='grey', main='Annual Salary')

# Analisi grafica per il dato qualitativo
pie(table(my.data$Gender), labels=c('Female','Male'))

# Relazione tra una variabile qualitativa euna quantitativa
#Distribuzione dell'esperieza dato il genere
boxplot(my.data$Salary~my.data$Gender, main='Salary given Gender',col=c('pink','blue'), las=2, ylab='Salary', cex.axis=0.7)

# Grafico di dispersione del salario e esperienza distinguendo tra genere
plot(my.data$Experience, my.data$Salary, main='Salary vs Experience',xlab='Experience', ylab='Salary', las=2, cex.axis=0.7)
points(my.data$Experience[my.data$Gender == 'Female'], my.data$Salary[my.data$Gender == 'Female'], col='pink', pch=19)
points(my.data$Experience[my.data$Gender == 'Male'], my.data$Salary[my.data$Gender == 'Male'], col='blue', pch=19)
legend('topleft', pch=c(19,19), c('Female','Male'), col=c('pink','blue'), bty='n')
